{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHMnPL1UQtppBVbRK/x5+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/webbigdata-jp/python_sample/blob/main/gemma_2_2b_jpn_it_tranlate_batch_translation_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [gemma-2-2b-jpn-it-translaten](https://huggingface.co/webbigdata/gemma-2-2b-jpn-it-translate) batch translaion sample.\n",
        "\n",
        "アップロードされたファイルを英語から日本語、または日本語から英語に一括翻訳し、ファイルとして出力します。  \n",
        "Translate uploaded file from English to Japanese or from Japanese to English in bulk and output it as file.  \n",
        "\n",
        "左側の三角形状のアイコンを順にクリックして実行してください  \n",
        "Click the triangle icons on the left in order to execute the.  \n",
        "\n",
        "- .txtファイルのみに対応しています\n",
        "- Only .txt files are supported\n",
        "- 翻訳の品質にはブレがあり高品質に翻訳できる文体とそうでない文体の差が大きいです\n",
        "- There is a large discrepancy in translation quality, and there is a large difference between styles that can be translated with high quality and those that cannot."
      ],
      "metadata": {
        "id": "zoGakEryj7U5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%shell\n",
        "#@title Install library\n",
        "pip install -U transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tg0N9WMLUd9s",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload Text File(.txt only)\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "ySYPemnqJikW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Translation Setting\n",
        "Translation_direction = 'English to Japanese' #@param [\"Japanese to English\", \"English to Japanese\"]"
      ],
      "metadata": {
        "id": "Bkq2xQspJixB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Writing Style Setting\n",
        "Writing_style = 'business' #@param [\"business\", \"formal\", \"casual\", \"slang\"]\n"
      ],
      "metadata": {
        "id": "2-lRmjpwnuMp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#@title Download Model (may take a few minutes)\n",
        "\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "def get_torch_dtype():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        prop = torch.cuda.get_device_properties(device)\n",
        "        # Ampere (Compute Capability 8.0 above), for example L4 support bfloat16, but T4 not support.\n",
        "        if prop.major >= 8:\n",
        "            return torch.bfloat16\n",
        "    return torch.float16\n",
        "\n",
        "model_name = \"webbigdata/gemma-2-2b-jpn-it-translate\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=get_torch_dtype(),\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n"
      ],
      "metadata": {
        "id": "nlRdFXLHKxoO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Translate line by line and write to file\n",
        "import chardet  # Required for character encoding detection\n",
        "\n",
        "\n",
        "def translate_file():\n",
        "    system_prompt =  \"\"\"You are a highly skilled professional Japanese-English and English-Japanese translator. Translate the given text accurately, taking into account the context and specific instructions provided. Steps may include hints enclosed in square brackets [] with the key and value separated by a colon:. Only when the subject is specified in the Japanese sentence, the subject will be added when translating into English. If no additional instructions or context are provided, use your expertise to consider what the most appropriate context is and provide a natural translation that aligns with that context. When translating, strive to faithfully reflect the meaning and tone of the original text, pay attention to cultural nuances and differences in language usage, and ensure that the translation is grammatically correct and easy to read. After completing the translation, review it once more to check for errors or unnatural expressions. For technical terms and proper nouns, either leave them in the original language or use appropriate translations as necessary. Take a deep breath, calm down, and start translating.\"\"\"\n",
        "    instruct = \"\"\n",
        "\n",
        "    filename = next(iter(uploaded.keys()))\n",
        "    with open(filename, \"rb\") as file:  # Read file in binary mode\n",
        "        binary_content = file.read()\n",
        "        detected_encoding = chardet.detect(binary_content)[\"encoding\"] or \"sjis\"\n",
        "        content = binary_content.decode(detected_encoding).encode(\"utf-8\").decode(\"utf-8\")  # Convert to utf-8\n",
        "\n",
        "        if Translation_direction == 'Japanese to English':\n",
        "            sentences = [s for s in content.split('。') if s]\n",
        "            sentences = [item for sublist in [s.split('\\n') for s in sentences] for item in sublist]\n",
        "            instruct = \"Translate Japanese to English.\"\n",
        "        else:\n",
        "            sentences = [s for s in content.split('.') if s]\n",
        "            sentences = [item for sublist in [s.split('\\n') for s in sentences] for item in sublist]\n",
        "            instruct = \"Translate English to Japanese.\"\n",
        "\n",
        "    style = \"When translating, please use the following hints:\\n[writing_style: {Writing_style}]\"\n",
        "\n",
        "    initial_messages = [\n",
        "        {\"role\": \"user\", \"content\": system_prompt + \"\\n\\n\" + instruct + \"\\n\" + \"When translating, please use the following hints:\\n[writing_style: {Writing_style}]\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"OK\"}\n",
        "    ]\n",
        "    messages = initial_messages.copy()\n",
        "\n",
        "    output_path = filename.replace('.txt', '_Ja_to_En.txt') if Translation_direction == 'Japanese to English' else filename.replace('.txt', '_En_to_Ja.txt')\n",
        "    with open(output_path, 'w', encoding='utf-8') as hyp_file:\n",
        "        for line in sentences:\n",
        "            if line == \"\":\n",
        "                model_response = \"\"\n",
        "                hyp_file.write('\\n')\n",
        "                continue\n",
        "\n",
        "            messages.append({\"role\": \"user\", \"content\": line.strip()})\n",
        "            inputs = tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=True,\n",
        "                add_generation_prompt=True,\n",
        "                return_tensors=\"pt\",\n",
        "            ).to(\"cuda\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                generated_ids = model.generate(\n",
        "                input_ids=inputs,\n",
        "                num_beams=3, max_new_tokens=1200, do_sample=True, temperature=0.5, top_p=0.3,\n",
        "                repetition_penalty=1.0\n",
        "            )\n",
        "            full_outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "            model_marker = \"\\nmodel\\n\"\n",
        "            model_response = full_outputs[0].split(model_marker)[-1].strip()\n",
        "\n",
        "            hyp_file.write(model_response + '\\n')\n",
        "            messages.append({\"role\": \"assistant\",  \"content\": model_response})\n",
        "            print(f\"Translated: {line.strip()} -> {model_response}\")\n",
        "\n",
        "            if len(messages) > 8:  # 2 (initial) + 6 (new) = 8\n",
        "                messages = initial_messages + messages[-6:]\n",
        "\n",
        "    print(f\"Translation compleated. please download files.: {output_path}\")\n",
        "    files.download(output_path)\n",
        "\n",
        "translate_file()\n"
      ],
      "metadata": {
        "id": "sJ3BhGnTKCmK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 謝辞 Acknowledgment\n",
        "\n",
        "### Referenced models.\n",
        "Original Model  \n",
        "google/gemma-2-2b-jpn-it  \n",
        "https://huggingface.co/google/gemma-2-2b-jpn-it\n",
        "\n",
        "This Model  \n",
        "webbigdata/gemma-2-2b-jpn-it-translate  \n",
        "https://huggingface.co/webbigdata/gemma-2-2b-jpn-it-translate\n",
        "\n",
        "\n",
        "このスクリプトは[webbigdata](https://webbigdata.jp/)によって作成されました  \n",
        "This script was created by [webbigdata](https://webbigdata.jp/).  "
      ],
      "metadata": {
        "id": "XRsZhDqOmaCC"
      }
    }
  ]
}