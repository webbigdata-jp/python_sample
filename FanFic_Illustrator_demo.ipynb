{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UbdUkAusy1_N",
        "3w85X9ciyzlz"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMp1Yd3AENZr0APk9fczO7L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/webbigdata-jp/python_sample/blob/main/FanFic_Illustrator_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [FanFic-Illustrator](https://huggingface.co/webbigdata/FanFic-Illustrator) Demo.\n",
        "\n",
        "Enter your original story or fan fiction and we'll create illustrations for it.  \n",
        "オリジナル小説や二次創作したファン小説を入力すると、その文章用の挿絵を作成します  \n",
        "\n",
        "\n",
        "## How to run/動かし方\n",
        "\n",
        "If you are on a github page, click the Open in Colab button at the top of the screen to launch Colab.\n",
        "\n",
        "あなたが見ているのがgithubのページである場合、画面上部に表示されているOpen in Colabボタンを押してColabを起動してください\n",
        "\n",
        "![github.png](data:image/png;base64,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)\n",
        "\n",
        "Next, run each cell one by one (i.e. click the \"▷\" in order as shown in the image below).  \n",
        "次に、セルを１つずつ実行(つまり、以下の画像のような「▷」を順番にクリック)してください  \n",
        "\n",
        "![cell.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAANAAAAAtCAIAAABQynLkAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAUqSURBVHhe7Zy9axRBFMD92yTkQCRycKSwCZLTqwXFFBJyILGRVCE2lyLXCCFYibkUEfwDLiJJkeqKWF2EQAipUsT3Zt7sztd+zOzeGuP7sZy7s/O18377dk9NHtwyTIOwcEyjsHBMo7BwTKOwcEyjsHBMo0QKd3Nzc319fXl5ecEwIcQIB6pRa4YJJFi4q6srasow4YQJx7mNqUiAcPDeRo0YJpYA4Ti9MdUJEI6/kzLVCRCOWjBMBWYi3Pn5+e7u7urqak8AO3AIhXSa+Y+pXzhwq91uP3SAQjhFlf4Ox4Pu/NoBHfxzHA+eLQ2O5ScVEaO1Vn9f7PnOOhz057rbRZVmRc3CbW5ukl8ZQAWqWsDkcOv9px90UBMiMCfbS635Od8W6yJ0+2xwQgclKTIjdUgDbhgYSH5SkaBAuP2+faXupq4durJPGVt/JOtFU6dwkMBIq1zK5bm4bDQ93XvbeZTREFSDO1t+UlEKRMVphXPQlztDkbLCgQ1JwIKFc9KSqVEqnFaYMeH7keHgFc16ko5Go+XlZTrQgGol3ufChZse7bxalAvtbUgx1oTTo24JJyNn1Rcxdt1yhdPyhJYSsM9o4eTo/gSTVvZ3m53Uaauct8pTm3BuepPlw+FwYWGBihQlkpwj3GTyi/YygBu383Lny0dYXJ9w6kkkBNo3MwGsuC6csE3F28qIGDxTBU84RQWnZgnh7JxKG03ANVtSJJzF/chw8FWUbFLQiYuLs7OzjY0NKhVAZTqXiSnc9HC9M995N8pz7uRoPKXwe4STWkC8YSc/w1miQHjMBAA1sZXskDbXA5y/FfsSwilMJ2hEswdMeOkEUuG0Qq+dOcJpiTl7y5t2CWoTrtfrkU0KOqEYj8crKyvyFFSm0kycDPdz+PxxkXNAhnAYs66IVpFwSXQlHjMsBXFEO7QYeCeoqEg54bC5PkQ6ojfJ5We4UhoZwyVY914d3GnhXu9NDL59eNoqzHM+4YRk+BiFZZXCiWpquTGESjgYV4+o4z1QKBxU8MVJVzlfuMR+QhvRPiVmmFxFfrdUubs9MG8qG7wiMf9kpz7u9CNVCWFti+vf4dmZgTDJUgTCACWUNqCCFI4yEBmmAplmC8S34tRPAtbRhfMmIcBw1zGDpiFwejjo236Iy5QLsjYwcra2UHreojynJpBeJjYxkjHOk4ZLLj/jForgzn5p8HD6+c2TVnvt64SOvYhIWMJJygmnB97ISQrDGwRH9BpmYsbMEg4GSqNuZVCnsgVdl9q3a+K4UjXzXlLlYk2OkzY4k2T0RDg5iuFlJLUJV/dfi9iUsg0oL5xcbtx04bT4+W5rwwwiK6XpYILRVdDMQIO1Ph2hPSU6xuge4VJM4URl6wKxRL86TTgAr91ZkFBqEw5wk5yXmPQ2Pdp6sVhsG1BSOCpLSYSTARYimosrU4KnLdbPyUDUYZI2BNIMEULjFE0SSOZpRt0kx2MXEo4GlaskLoqauCvjDG0bGU6dwgH1/dOWw2/6M5pUOLHc7paVRbAhVsi5uTHweldqw9yTOqTh79MMsKqTNTEc1DoFTXzCGdNze/Ok7eSBW00vl5qFAyCBWc9WCRTGvbrVBQXevY8FWoZjZkj9wgHwigZuwVfRngB24DDivY25f8xEOIbJIkA4/i/mTHUChOMfomGqEyAc/5ggU50A4QBOckxFwoQD+Fc9MFUIFg7gPMdEEyMcwL+ui4kjUjiGiYOFYxqFhWMahYVjGoWFYxqFhWMahYVjGuT29g//C8PBV5aV1wAAAABJRU5ErkJggg==)\n"
      ],
      "metadata": {
        "id": "k-Rs1yFEdLdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Required Libraries"
      ],
      "metadata": {
        "id": "UbdUkAusy1_N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "lyrygqjF6-09"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%shell\n",
        "#@title Install Required Libraries\n",
        "\n",
        "pip install diffusers==0.32.2 transformers==4.49.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setting Up\n",
        "\n",
        "2つのモデルをダウンロードするためやや時間がかかります  \n",
        "This will take some time as two models will be downloaded.  "
      ],
      "metadata": {
        "id": "3w85X9ciyzlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (1)Dependent Libraries and Utility Functions/依存ライブラリとユーティリティ関数\n",
        "# ======== セル1: 依存ライブラリとユーティリティ関数 ========\n",
        "import gc\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import uuid\n",
        "from PIL import Image, PngImagePlugin\n",
        "from datetime import datetime\n",
        "from typing import Callable, Dict, Optional, Tuple, Any, List\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Diffusersのインポート\n",
        "from diffusers import (\n",
        "    EulerAncestralDiscreteScheduler,\n",
        "    AutoencoderKL,\n",
        "    StableDiffusionXLPipeline,\n",
        ")\n",
        "\n",
        "# ロギング設定\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# 定数\n",
        "MAX_SEED = np.iinfo(np.int32).max\n",
        "OUTPUT_DIR = \"./outputs\"\n",
        "MODEL = \"cagliostrolab/animagine-xl-4.0\"\n",
        "MIN_IMAGE_SIZE = 512\n",
        "MAX_IMAGE_SIZE = 2048\n",
        "DEFAULT_NEGATIVE_PROMPT = \"lowres, bad anatomy, bad hands, text, error, missing finger, extra digits, fewer digits, cropped, worst quality, low quality, low score, bad score, average score, signature, watermark, username, blurry\"\n",
        "DEFAULT_ASPECT_RATIO = \"832 x 1216\"\n",
        "DEFAULT_SERIES = \"original\"\n",
        "DEFAULT_CHARACTER = \"original character\"\n",
        "DEFAULT_CATEGORY = \"general\"\n",
        "\n",
        "# ランダムシード設定\n",
        "def seed_everything(seed: int) -> torch.Generator:\n",
        "    \"\"\"乱数シードを設定する関数\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    generator = torch.Generator()\n",
        "    generator.manual_seed(seed)\n",
        "    return generator\n",
        "\n",
        "# アスペクト比処理\n",
        "def parse_aspect_ratio(aspect_ratio: str) -> Optional[Tuple[int, int]]:\n",
        "    \"\"\"アスペクト比を解析する関数\"\"\"\n",
        "    if aspect_ratio == \"Custom\":\n",
        "        return None\n",
        "    width, height = aspect_ratio.split(\" x \")\n",
        "    return int(width), int(height)\n",
        "\n",
        "def aspect_ratio_handler(\n",
        "    aspect_ratio: str, custom_width: int, custom_height: int\n",
        ") -> Tuple[int, int]:\n",
        "    \"\"\"アスペクト比に合わせて解像度を処理する関数\"\"\"\n",
        "    if aspect_ratio == \"Custom\":\n",
        "        return custom_width, custom_height\n",
        "    else:\n",
        "        width, height = parse_aspect_ratio(aspect_ratio)\n",
        "        return width, height\n",
        "\n",
        "# スケジューラ取得\n",
        "def get_scheduler(scheduler_config: Dict, name: str) -> Optional[Callable]:\n",
        "    \"\"\"スケジューラを取得する関数\"\"\"\n",
        "    scheduler_factory_map = {\n",
        "        \"Euler a\": lambda: EulerAncestralDiscreteScheduler.from_config(\n",
        "            scheduler_config\n",
        "        ),\n",
        "    }\n",
        "    return scheduler_factory_map.get(name, lambda: None)()\n",
        "\n",
        "# メモリ解放\n",
        "def free_memory() -> None:\n",
        "    \"\"\"GPU及びシステムメモリを解放する関数\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "    gc.collect()\n",
        "\n",
        "# プロンプト前処理\n",
        "def preprocess_prompt(\n",
        "    style_dict,\n",
        "    style_name: str,\n",
        "    positive: str,\n",
        "    negative: str = \"\",\n",
        "    add_style: bool = True,\n",
        ") -> Tuple[str, str]:\n",
        "    \"\"\"スタイルを適用してプロンプトを前処理する関数\"\"\"\n",
        "    p, n = style_dict.get(style_name, style_dict[\"(None)\"])\n",
        "\n",
        "    if add_style and positive.strip():\n",
        "        formatted_positive = p.format(prompt=positive)\n",
        "    else:\n",
        "        formatted_positive = positive\n",
        "\n",
        "    combined_negative = n\n",
        "    if negative.strip():\n",
        "        if combined_negative:\n",
        "            combined_negative += \", \" + negative\n",
        "        else:\n",
        "            combined_negative = negative\n",
        "\n",
        "    return formatted_positive, combined_negative\n",
        "\n",
        "# 画像保存\n",
        "def save_image(image, metadata, output_dir):\n",
        "    \"\"\"生成された画像を保存する関数\"\"\"\n",
        "    current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"image_{current_time}.png\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    metadata_str = json.dumps(metadata)\n",
        "    info = PngImagePlugin.PngInfo()\n",
        "    info.add_text(\"parameters\", metadata_str)\n",
        "    image.save(filepath, \"PNG\", pnginfo=info)\n",
        "    return filepath\n",
        "\n",
        "# パイプラインロード\n",
        "def load_pipeline(model_name: str, device: torch.device, vae: Optional[AutoencoderKL] = None) -> Any:\n",
        "    \"\"\"Stable Diffusionパイプラインをロードする関数\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Loading pipeline from {model_name}...\")\n",
        "\n",
        "        # モデルIDからロード\n",
        "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "            model_name,\n",
        "            vae=vae,\n",
        "            torch_dtype=torch.float16,\n",
        "            use_safetensors=True,\n",
        "            custom_pipeline=\"lpw_stable_diffusion_xl\",\n",
        "            add_watermarker=False\n",
        "        )\n",
        "\n",
        "        pipe.to(device)\n",
        "        logger.info(\"Pipeline loaded successfully!\")\n",
        "        return pipe\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load pipeline: {str(e)}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "# 画像の解像度を前処理\n",
        "def preprocess_image_dimensions(width, height):\n",
        "    \"\"\"画像の解像度を前処理する関数\"\"\"\n",
        "    # 最小サイズと最大サイズの範囲内に収める\n",
        "    width = max(MIN_IMAGE_SIZE, min(MAX_IMAGE_SIZE, width))\n",
        "    height = max(MIN_IMAGE_SIZE, min(MAX_IMAGE_SIZE, height))\n",
        "\n",
        "    # 8の倍数に調整（Stable Diffusionの要件）\n",
        "    width = width - (width % 8)\n",
        "    height = height - (height % 8)\n",
        "\n",
        "    return width, height\n",
        "\n",
        "# スタイル定義\n",
        "styles = [\n",
        "    {\"name\": \"(None)\", \"prompt\": \"{prompt}\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"Anim4gine\", \"prompt\": \"{prompt}, depth of field, faux traditional media, painterly, impressionism, photo background\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"Painting\", \"prompt\": \"{prompt}, painterly, painting (medium)\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"Pixel art\", \"prompt\": \"{prompt}, pixel art\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"1980s\", \"prompt\": \"{prompt}, 1980s (style), retro artstyle\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"1990s\", \"prompt\": \"{prompt}, 1990s (style), retro artstyle\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"2000s\", \"prompt\": \"{prompt}, 2000s (style), retro artstyle\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"Toon\", \"prompt\": \"{prompt}, toon (style)\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"Lineart\", \"prompt\": \"{prompt}, lineart, thick lineart\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"Art Nouveau\", \"prompt\": \"{prompt}, art nouveau\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"Western Comics\", \"prompt\": \"{prompt}, western comics (style)\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"3D\", \"prompt\": \"{prompt}, 3d\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"Realistic\", \"prompt\": \"{prompt}, realistic, photorealistic\", \"negative_prompt\": \"\"},\n",
        "    {\"name\": \"Neonpunk\", \"prompt\": \"{prompt}, neonpunk\", \"negative_prompt\": \"\"}\n",
        "]\n",
        "\n",
        "def get_style_dict():\n",
        "    \"\"\"スタイル辞書を生成する関数\"\"\"\n",
        "    return {style[\"name\"]: (style[\"prompt\"], style.get(\"negative_prompt\", \"\")) for style in styles}\n",
        "\n",
        "\n",
        "\n",
        "series_and_charcters = {\n",
        "    \"vocaloid\": {\n",
        "        \"description\": \"ヤマハが開発した音声合成技術、およびそのキャラクター。ユーザーが作成した楽曲を、キャラクターが歌う。初音ミクを筆頭に、様々なキャラクターが存在する。音楽シーンに大きな影響を与えている。\",\n",
        "        \"characters\": {\n",
        "            \"hatsune miku\": {\n",
        "                \"gender\": \"female\",\n",
        "                \"description\": \"ツインテールのバーチャル・シンガー。水色がイメージカラー。様々なジャンルの楽曲を歌いこなす。世界中で人気のキャラクター。ライブコンサートも開催されている。\"\n",
        "            },\n",
        "            \"kagamine rin\": {\n",
        "                \"gender\": \"female\",\n",
        "                \"description\": \"ショートヘアのバーチャル・シンガー。黄色がイメージカラー。鏡音レンとデュエット曲を歌うことが多い。元気で明るい歌声が特徴。ツンデレな性格とされる。\"\n",
        "            },\n",
        "            \"kagamine len\": {\n",
        "                \"gender\": \"male\",\n",
        "                \"description\": \"ショートヘアのバーチャル・シンガー。黄色がイメージカラー。鏡音リンとデュエット曲を歌うことが多い。力強い歌声が特徴。クールな性格とされる。\"\n",
        "            },\n",
        "            \"megurine luka\": {\n",
        "                \"gender\": \"female\",\n",
        "                \"description\": \"ロングヘアのバーチャル・シンガー。ピンク色がイメージカラー。日本語と英語のバイリンガル。大人っぽい歌声が特徴。クールビューティーな性格とされる。\"\n",
        "            },\n",
        "        }\n",
        "    },\n",
        "    \"touken ranbu\": {\n",
        "        \"description\": \"名だたる刀剣が戦士の姿となった「刀剣男士」を収集・育成するシミュレーションゲーム。歴史上の合戦場を舞台に、時間遡行軍と戦う。美麗なイラストと、豪華声優陣が魅力。女性を中心に人気を集めている。\",\n",
        "        \"characters\": {\n",
        "            \"kashuu kiyomitsu\": {\n",
        "                \"gender\": \"male\",\n",
        "                \"description\": \"加州清光は、新選組 沖田総司の愛刀として知られる打刀。赤いマフラーと、黒いコートが特徴。「可愛く」いることを大切にしており、爪紅を塗っている。戦闘では、素早い動きで敵を翻弄する。\"\n",
        "            },\n",
        "            \"mikazuki munechika\": {\n",
        "                \"gender\": \"male\",\n",
        "                \"description\": \"三日月宗近は、天下五剣の一つで、最も美しいとされる太刀。平安時代の装束を身に纏い、優雅な雰囲気を漂わせる。「じじい」口調で話し、マイペースな性格。戦闘では、華麗な太刀筋で敵を圧倒する。\"\n",
        "            },\n",
        "            \"tsurumaru kuninaga\": {\n",
        "                \"gender\": \"male\",\n",
        "                \"description\": \"鶴丸国永は、平安時代の刀工・五条国永作の太刀。白い装束と、鶴を思わせる意匠が特徴。驚きを求める性格で、いたずら好き。戦闘では、軽快な動きと、トリッキーな技を繰り出す。\"\n",
        "            },\n",
        "            \"yamato-no-kami yasusada\": {\n",
        "                \"gender\": \"male\",\n",
        "                \"description\": \"沖田総司の刀の化身。黒髪を高くまとめ、青い目をしており、左目の下にほくろがある。白のマフラー、新撰組の羽織、黒の「花嫁の籠手」タイプの手袋、紺色の袴、黒の足袋、青の鼻緒の草履が標準の服装。普段は気楽な性格だが、戦闘になると冷酷でサディスティック\"\n",
        "            },\n",
        "            \"namazuo toushirou\":{\n",
        "                \"gender\": \"male\",\n",
        "                \"description\": \"薙刀から改造された脇差。外向的で明るく、ややぼんやりした性格。長い黒髪をポニーテールに結び、目立つアホ毛と紫色の目をしている。普段の服装は、軍服で、黒のネクタイと片方の肩に黒の袖がある。\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"kantai collection\":{\n",
        "        \"description\": \"各キャラクターは、第二次世界大戦の海軍の軍艦を擬人化した萌えキャラクターで「艦娘」と呼ばれるかわいい女の子として描かれています。各女の子の身体的特徴、外見、性格は、実際の船と何らかの形で相関しています。\",\n",
        "        \"characters\": {\n",
        "            \"kaga (kancolle)\": {\n",
        "                \"gender\": \"female\",\n",
        "                \"description\": \"日本の航空母艦加賀の擬人化。ストイックな性格。サイドポニーテールの長い茶色の髪、つり目のような茶色の目、大きな胸。白い着物トップスと青いプリーツスカートの上に黒い胸当て、黒いサイハイソックス、厚底靴。伝統的な弓、矢筒\"\n",
        "            },\n",
        "            \"shimakaze (kancolle)\": {\n",
        "                \"gender\": \"female\",\n",
        "                \"description\": \"長いブロンドの髪と灰色の目。クロップ丈のセーラー服、ストライプのニーソックス、白いエルボーグローブ、お尻が見える黒いハイレグパンツの短いミニスカート、そして長く垂れ下がった「耳」の付いた黒いヘアバンドを着用\",\n",
        "            },\n",
        "            \"hibiki (kancolle)\": {\n",
        "                \"gender\": \"female\",\n",
        "                \"description\": \"暁型は白と濃紺のセーラー服、黒いレッグウェアも着用しています。響自身は白、水色、水色、または灰色の長い髪、青または灰色の目を持ち、黒いニーソックスとフラットキャップを着用しています。\"\n",
        "            },\n",
        "            \"shigure (kancolle)\": {\n",
        "                \"gender\": \"female\",\n",
        "                \"description\": \"艦隊これくしょんアニメ第2期の主人公。中くらいの長さのダークブラウン/黒髪で、肩に編んだアホ毛と青い目をしている。デフォルトの服装は白露型の制服で、黒いセーラー服、黒いソックス、茶色のローファー。\"\n",
        "            },\n",
        "            \"kongou (kancolle)\": {\n",
        "                \"gender\": \"female\",\n",
        "                \"description\": \"紫色の瞳、長い茶色の髪を二つにまとめたお団子ヘア、アホ毛。黒色の袴とサイハイブーツを履いた改良型の巫女服を着用し、特徴的な羽根付きヘアバンドを着用\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"virtual_youtuber\":{\n",
        "        \"description\": \"オンライン動画やライブストリーミングで 3D または 2D のデジタル アバターを使用し、キャラクターを演じることが多いコンテンツ クリエイターおよびパーソナリティです。\",\n",
        "        \"characters\":{\n",
        "            \"shigure ui (vtuber)\":{\n",
        "                \"gender\": \"female\",\n",
        "                \"description\":\"彼女は短い明るい茶色またはブロンドの髪と緑色の目をしており、通常の髪型はフレンチサイドの三つ編みで、ポンポンの髪飾りで留めたヘアリングと、ななめに流した前髪で構成されています。\"\n",
        "            },\n",
        "            \"dokibird (vtuber)\":{\n",
        "                \"gender\": \"female\",\n",
        "                \"description\":\"伝説の泥棒とされる彼女は、彼女は青い襟付きシャツの上に黒いジャケットを着て、黄色のネッカチーフ、白いパンツ、黒い手袋、黒いカウボーイブーツを身に着けています。\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"original\":{\n",
        "        \"description\": \"特定の原作を持たない、オリジナルのシリーズです\",\n",
        "        \"characters\":{\n",
        "            \"original character\":{\n",
        "                \"gender\": \"不明\",\n",
        "                \"description\":\"特定の原作を持たない、オリジナルのキャラクターです\"\n",
        "            }\n",
        "        }\n",
        "     }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# 設定ファイル読み込み\n",
        "def load_config(config_path=None):\n",
        "    \"\"\"設定ファイルを読み込む関数\"\"\"\n",
        "    return {\n",
        "        \"model\": {\n",
        "            \"path\": MODEL,\n",
        "            \"min_image_size\": MIN_IMAGE_SIZE,\n",
        "            \"max_image_size\": MAX_IMAGE_SIZE,\n",
        "            \"output_dir\": OUTPUT_DIR\n",
        "        },\n",
        "        \"prompts\": {\n",
        "            \"default_negative\": DEFAULT_NEGATIVE_PROMPT,\n",
        "            \"default_aspect_ratio\": DEFAULT_ASPECT_RATIO\n",
        "        },\n",
        "        \"text_to_prompt\": {\n",
        "            \"enabled\": True,\n",
        "            \"default_category\": DEFAULT_CATEGORY,\n",
        "            \"default_series\": DEFAULT_SERIES,\n",
        "            \"default_character\": DEFAULT_CHARACTER\n",
        "        },\n",
        "        \"samplers\": {\n",
        "            \"name\": \"Euler a\"\n",
        "        },\n",
        "        \"aspect_ratios\": {\n",
        "            \"name\": DEFAULT_ASPECT_RATIO\n",
        "        },\n",
        "        \"styles\": styles\n",
        "    }\n",
        "\n",
        "\n",
        "# GPU強制解放関数（リスクあり）\n",
        "def force_gpu_memory_release():\n",
        "    try:\n",
        "        print(\"GPUメモリ解放を試みています...\")\n",
        "        # 既存のPyTorchモジュールへの参照をすべて削除\n",
        "        for obj in gc.get_objects():\n",
        "            try:\n",
        "                if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
        "                    # GPUメモリを使用しているテンソルをCPUに移動\n",
        "                    if obj.is_cuda:\n",
        "                        obj.data = obj.data.cpu()\n",
        "                        if hasattr(obj, 'grad') and obj.grad is not None:\n",
        "                            obj.grad.data = obj.grad.data.cpu()\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "        # ガベージコレクション強制実行\n",
        "        gc.collect()\n",
        "\n",
        "        # CUDA関連のキャッシュを解放\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.ipc_collect()\n",
        "\n",
        "        print(\"GPUメモリ解放処理が完了しました\")\n",
        "\n",
        "        # 現在のGPUメモリ使用状況を表示\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"現在のGPUメモリ使用量: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
        "            print(f\"キャッシュされたGPUメモリ: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPUメモリ解放中にエラーが発生しました: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "al8F1n-Fmpq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (2)Module for generating prompts/プロンプト生成のためのモジュール\n",
        "\n",
        "# ======== セル2: プロンプト生成のためのモジュール ========\n",
        "# グローバル変数\n",
        "_model = None\n",
        "_tokenizer = None\n",
        "\n",
        "def load_prompt_model():\n",
        "    \"\"\"プロンプト生成用のモデルをロードする関数\"\"\"\n",
        "    global _model, _tokenizer\n",
        "\n",
        "    # すでにロードされている場合はスキップ\n",
        "    if _model is not None and _tokenizer is not None:\n",
        "        return _model, _tokenizer\n",
        "\n",
        "    try:\n",
        "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "        #logger.info(\"Loading prompt generation model...\")\n",
        "\n",
        "        # 使用するモデル名\n",
        "        model_name = os.getenv(\"PROMPT_MODEL_NAME\", \"webbigdata/FanFic-Illustrator\")\n",
        "\n",
        "        # デバイス設定\n",
        "        device_map = \"auto\" if torch.cuda.is_available() else \"cpu\"\n",
        "        torch_dtype = torch.bfloat16 if torch.cuda.is_available() and hasattr(torch, 'bfloat16') else torch.float16\n",
        "        #logger.info(f\"Using device: {device_map} for prompt generation model\")\n",
        "\n",
        "        # モデルの読み込み\n",
        "        _model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch_dtype,\n",
        "            device_map=device_map,\n",
        "            use_cache=True,\n",
        "            low_cpu_mem_usage=True,\n",
        "        )\n",
        "\n",
        "        # トークナイザーの読み込み\n",
        "        _tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        # パッドトークンの設定\n",
        "        if _tokenizer.pad_token is None:\n",
        "            _tokenizer.pad_token = _tokenizer.eos_token\n",
        "\n",
        "        #logger.info(\"Prompt generation model loaded successfully!\")\n",
        "        return _model, _tokenizer\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load prompt generation model: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def unload_prompt_model():\n",
        "    \"\"\"メモリからモデルをアンロードする関数\"\"\"\n",
        "    global _model, _tokenizer\n",
        "\n",
        "    if _model is not None:\n",
        "        del _model\n",
        "        _model = None\n",
        "\n",
        "    if _tokenizer is not None:\n",
        "        del _tokenizer\n",
        "        _tokenizer = None\n",
        "\n",
        "    # メモリの解放\n",
        "    free_memory()\n",
        "\n",
        "    logger.info(\"Prompt generation model unloaded\")\n",
        "\n",
        "\n",
        "def generate_prompt(\n",
        "    novel_text: str,\n",
        "    series_name: str = \"original\",\n",
        "    character_name: str = \"original character\",\n",
        "    category: str = \"general\"\n",
        ") -> Tuple[str, str]:\n",
        "    \"\"\"テキストからプロンプトを生成する関数\"\"\"\n",
        "    try:\n",
        "        # モデルとトークナイザーの読み込み\n",
        "        model, tokenizer = load_prompt_model()\n",
        "        logger.info(\"Loading model, tokenizer is ok...\")\n",
        "\n",
        "        # 入力の検証\n",
        "        if not novel_text or novel_text.isspace():\n",
        "            return \"入力テキストが空です\", \"1girl, original character, anime style, highres\"\n",
        "\n",
        "        input_tokens = tokenizer.encode(novel_text)\n",
        "        if len(input_tokens) > 2000:\n",
        "          # 後半の2000トークンだけを使用\n",
        "          trimmed_tokens = input_tokens[-2000:]\n",
        "          novel_text = tokenizer.decode(trimmed_tokens)\n",
        "          logger.info(f\"Input text trimmed from {len(input_tokens)} to 2000 tokens\")\n",
        "\n",
        "        # 長すぎる入力のトリミング（トークン数の制限）\n",
        "        max_input_length = 4800\n",
        "\n",
        "        # システムプロンプト\n",
        "        system = \"あなたは文章の一説を指定ジャンル・キャラクターが登場するシーンに書き換え、そのシーンに合った挿絵を作成するために画像生成AI用プロンプトを作成する優秀なプロンプトエンジニアです\"\n",
        "\n",
        "        # ユーザープロンプト 2700 token\n",
        "        prompt = f\"\"\"### 小説のコンテキストを補足する情報\n",
        "content category: {category}\n",
        "series name: {series_name}\n",
        "series description: {series_and_charcters[series_name]['description']}\n",
        "character name: {character_name}\n",
        "character description: {series_and_charcters[series_name]['characters'][character_name]}\n",
        "\n",
        "### 小説データ\n",
        "{novel_text}\n",
        "\n",
        "まず<think>内で以下のように思考を整理します。\n",
        "\n",
        "<think>\n",
        "concept: イラストのコンセプトを考えます。小説の内容から主題、設定、雰囲気を理解し、どのようなイラストが最も適切か、全体の構成を考えます\n",
        "- 人数: 挿絵の中に登場させる人数を考えます。作品に登場する人物の数や重要性を考慮し、メインで描くべき人物やサブキャラクターについても検討してください\n",
        "- キャラクター名/シリーズ名: 既存作品のキャラクター/シリーズか、オリジナル作品かを考えます。既存作品の場合は、原作の設定や特徴を尊重した表現方法も考慮してください\n",
        "- ポーズ/構図: ポーズ/構図指定に使うタグを考えます。物語の場面において、キャラクターがどのような体勢/状況にあるのか、どのアングルから描くと効果的かを検討してください\n",
        "- 背景/環境: 背景/環境指定に使うタグを考えます。物語の舞台設定や時間帯、天候など、雰囲気を表現するために必要な背景要素を詳しく考えてください\n",
        "- 描画スタイル/テクニック: 描画スタイル/テクニックに使うタグを考えます。物語のジャンルや雰囲気に合わせて、どのような画風や技法が適しているかを検討してください\n",
        "- 身体的特徴/画面上の物体: 身体的特徴/画面上の物体に関連するタグを考えます。キャラクターの外見的特徴や、シーンに必要な小道具、アイテムなどを詳細に考えてください\n",
        "</think>\n",
        "\n",
        "改行の場所も含めて、この順序と書式を厳密に守ってください。\n",
        "各項目は上記の順序と書式で記述してください。具体的かつ詳細に説明し、十分な長さで考察してください（<think>タグ全体で600-800文字程度が望ましいです）\n",
        "\n",
        "その後、思考結果に基づき<prompt>内に英単語を18単語ほどカンマで区切って出力してください。キャラクター名/シリーズ名は指定されていたら必ず含めます\n",
        "日本語は使用しないでください。 最も重要で適切なタグを選び、有効なプロンプトとなるよう考慮してください\n",
        "\n",
        "### 使用可能な英単語\n",
        "出力時には以下のタグを優先して使用し、足りない場合は一般的な英単語で補足します\n",
        "masterpiece, best quality, highresなどの品質に関連するタグは後工程で付与するのでつけてはいけません\n",
        "\n",
        "**人数/性別**:\n",
        "- 風景や動物を中心に描画する時: no_human\n",
        "- 女性の人数: 1girl, 2girls, 3girls, multiple girls\n",
        "- 男性の人数: 1boy, 2boys, 3boys, multiple boys\n",
        "- 1girlや1boy指定時にキャラクター中心の構図にするために追加で指定: solo\n",
        "\n",
        "**ポーズ/構図**:\n",
        "- 視点: from above, from behind, from below, looking at viewer, straight-on, looking at another, looking back, out of frame, on back, from side, looking to the side, feet out of frame, sideways, three quarter view, looking up, looking down, looking ahead, dutch angle, high up, from outside, pov, vanishing point\n",
        "- 姿勢/行動: battle, chasing, fighting, leaning, running, sitting, squatting, standing, walking, arm up, arms up, against wall, against tree, holding, spread legs, lying, straddling, flying, holding weapon, clothes lift, hand on own cheek, scar on cheek, hand on another's cheek, kissing cheek, cheek-to-cheek, bandaid on cheek, finger to cheek, hands on another's cheeks, hand on own hip, hand over face, v, kneeling, arabesque (pose), body roll, indian style, standing on one leg, hugging own legs, seiza, nuzzle, unsheathing, holding weapon, holding sword, holding gun, trembling\n",
        "\n",
        "**背景/環境**:\n",
        "- 構図/芸術ジャンル: landscape, portrait, still life, group shot, cowboy shot, upper body, full body, detailed face, depth of field, intricate details, cinematic lighting, detailed background, detailed, extremely detailed, perfect composition, detailed face, solo focus, detailed face and body, character focus, intricate, sharp focus, male focus\n",
        "- 色彩/装飾: greyscale, sepia, blue theme, flat color, high contrast, limited palette, border, cinematic, scenery, rendered, contrast, rich contrast, volumetric lighting, high contrast, glowing\n",
        "- 背景/風景: checkered background, simple background, indoors, outdoors, jungle, mountain, beach, forest, city, school, cafe, white background, sky\n",
        "- 時間帯: day, night, twilight, morning, sunset, dawn, dusk\n",
        "- 天気: sunny, rain, snow, cloud, storm, wind, fogg\n",
        "\n",
        "**描画スタイル/テクニック**:\n",
        "- 技法: 3D, oekaki, pixel art, sketch, watercolor, oil painting, digital art, illustration, photorealistic, anime, monochrome, retro color, source anime, cg, realistic\n",
        "- 表現手法: animalization, personification, science fiction, cyberpunk, steampunk, fantasy, dark novel style, anime style, realistic style, graphic novel style, comic, concept art\n",
        "- 媒体/伝統的技法: traditional media, marker (medium), watercolor (medium), graphite (medium), official art, sketch, artbook, cover\n",
        "- 絵柄の年代(指定された時のみ利用): newest, year 1980, year 2000, year 2010, year 1990, year 2020\n",
        "\n",
        "**身体的特徴/画面上の物体**:\n",
        "- キャラクター属性/職業/クラス: student, teacher, soldier, knight, wizard, ninja, doctor, artist, musician, athlete, virtual youtuber, chibi, maid, miko\n",
        "- 表情: angry, blush stickers, drunk, grin, aroused, happy, sad, smile, laugh, crying, surprised, worried, nervous, serious, drunk, blush, aroused, :d, tongue out, sweatdrop, tongue out, :o, tears, tearing up, scared\n",
        "\n",
        "- 身体的特徴: {{'髪型/髪色': ['long hair', 'short hair', 'twintails', 'ponytail', 'braid', 'bun', 'curly hair', 'straight hair', 'messy hair', 'blonde hair', 'black hair', 'brown hair', 'red hair', 'blue hair', 'green hair', 'white hair', 'purple hair', 'grey hair', 'ahoge', 'sidelocks', 'side ponytail', 'perfect hair', 'tail', 'multicolored hair', 'wavy hair', 'bangs', 'blunt bangs', 'twintails', 'hair between eyes', 'very long hair', 'braid', 'curly hair', 'braided ponytail', 'hand in own hair', 'hair over one eye', 'hair flower', 'two-tone hair', 'streaked hair', 'two side up'], '目の色': ['blue eyes', 'brown eyes', 'green eyes', 'red eyes', 'black eyes', 'purple eyes', 'yellow eyes', 'heterochromia', 'detailed eyes', 'glowing eyes', 'beatiful eyes', 'closed eyes', 'one eye closed'], '身体部位': ['bare shoulders', 'bare arms', 'bare legs', 'barefoot', 'abs', 'flat chest', 'small breasts', 'medium breasts', 'asymmetrical breasts', 'pointy breasts', 'sagging breasts', 'clenched teeth', 'pointy ears', 'perfect anatomy', 'closed mouth', 'long sleeves', 'open mouth', 'pale skin', 'collarbone', 'midriff', 'perfect anatomy', 'bare arms', 'thighs', 'parted lips', 'tongue', 'tanlines', 'dot nose', 'goggles on head', 'armpits', 'nail polish', 'mole', 'feet', 'lips', 'dark-skinned female', 'zettai ryouiki', 'shiny skin'], '身体部位(獣人、擬人化時のみ使用)': ['animal ears', 'cat ears', 'horse ears', 'horse girl', 'fang', 'teeth', 'horns', 'tail'], '服装/装飾品': ['uniform', 'suit', 'dress', 'casual wear', 'formal wear', 'belt', 'detached sleeves', 'swimsuit', 'kimono', 'armor', 'hat', 'glasses', 'white shirt', 'shirt', 'jewelry', 'necklace', 'earrings', 'bracelet', 'watch', 'ribbon', 'hair ribbon', 'scarf', 'gloves', 'boots', 'high heels', 'hair ornament', 'jacket', 'glasses', 'skirt', 'long sleeves', 'short sleeves', 'thighhighs', 'underwear', 'school uniform', 'swimsuit', 'panties', 'hair bow', 'bikini', 'miniskirt', 'fingerless gloves', 'bowtie', 'serafuku', 'japanese clothes', 'choker', 'pants', 'wings', 'open clothes', 'pantyhose', 'pleated skirt', 'frills', 'necktie', 'shorts', 'miko', 'collared shirt', 'leather armor', 'hairband', 'shoes', 'sleeveless', 'alternate costume', 'socks', 'fingering', 'denim shorts', 'epaulettes', 'santa costume', 'ribbon-trimmed sleeves', 'black bowtie', 'gym uniform', 'white bra', 'angel wings', 'crossdressing', 'cuffs', 'halo', 'high heels', 'apron', 'red bow', 'vest', 'open jacket', 'white panties', 'leotard', 'coat', 'black jacket', 'high heels', 'black pantyhose', 'see-through', 'miniskirt', 'elbow gloves', 'wide sleeves', 'white thighhighs', 'fur trim', 'plaid', 'one-piece swimsuit', 'maid headdress', 'ascot', 'high-waist skirt']}}\n",
        "- 体液: blood, saliva, sweat, tears\n",
        "- 前景/持ち物/操作物: sword, katana, sheath, gun, book, phone, bag, umbrella, instrument, vehicle, food, drink, guitar, piano, violin, drums, flute, car, bicycle, motorcycle, airplane, ship, flower, weapon, heart, speech bubble, carriage, locomotive, shovel\n",
        "- 生物: dog, cat, horse, bird, fish, crab, dragon, unicorn, monster, fox, wolf, bear, tiger, lion, dragon, fairy, ghost, zombie, vampire\n",
        "\n",
        "**性的表現（sensitive, nsfw, explicitのいずれかを指定した時のみ使用可）**:\n",
        "- 身体部位女性専用: cleavage, backboob, sideboob, underboob, navel, huge breasts, large breasts\n",
        "- 身体部位男性専用: topless male, necktie between pectorals, loose necktie, bare pectorals, male underwear, fundoshi\n",
        "- 身体部位共通: open shirt, unbuttoned shirt, seductive smile, bare back, groin, groin tendon, midriff\n",
        "\n",
        "### 出力\n",
        "\"\"\"\n",
        "\n",
        "        # メッセージ形式に整形\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "\n",
        "        # トークナイゼーション\n",
        "        inputs = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(model.device)\n",
        "        logger.info(\"tokenizer.apply_chat_template is ok...\")\n",
        "\n",
        "        # 長すぎる入力のトリミング\n",
        "        if inputs.shape[1] > max_input_length:\n",
        "            inputs = inputs[:, :max_input_length]\n",
        "            logger.warning(f\"Input tokens were too many and have been truncated to {max_input_length}\")\n",
        "\n",
        "        # 生成\n",
        "        logger.info(\"before torch.no_grad\")\n",
        "        with torch.no_grad():\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=inputs,\n",
        "                num_beams=3,\n",
        "                max_new_tokens=400,\n",
        "                do_sample=True,\n",
        "                temperature=0.5,\n",
        "                top_p=0.95,\n",
        "                repetition_penalty=1.0,\n",
        "                top_k=40,\n",
        "                min_p=0.00,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "            )\n",
        "\n",
        "        logger.info(\"after torch.no_grad\")\n",
        "        # デコード\n",
        "        full_outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "        # モデルが生成したメッセージ部分だけを抽出\n",
        "        model_markers = [\"assistant\\n\", \"assistant:\\n\", \"assitant\\n\"]\n",
        "        model_response = full_outputs[0]\n",
        "\n",
        "        for marker in model_markers:\n",
        "            if marker in model_response:\n",
        "                model_response = model_response.split(marker)[-1].strip()\n",
        "                break\n",
        "\n",
        "        # 思考過程とプロンプトの抽出\n",
        "        thinking = \"\"\n",
        "        prompt_text = \"\"\n",
        "\n",
        "        if \"<think>\" in model_response and \"</think>\" in model_response:\n",
        "            thinking = model_response.split(\"<think>\")[1].split(\"</think>\")[0].strip()\n",
        "\n",
        "        def clean_prompt_text(text):\n",
        "            # 削除するタグのリスト\n",
        "            tags_to_remove = [\n",
        "                \"masterpiece\", \"high score\", \"great score\", \"absurdres\",\n",
        "                \"highres\", \"original character\", \"original series\",\n",
        "                \"general\", \"sensitive\", \"nsfw\", \"explicit\"\n",
        "            ]\n",
        "\n",
        "            # テキストを単語に分割して処理\n",
        "            words = []\n",
        "            current_words = text.split(',')\n",
        "\n",
        "            # 各単語をトリムして処理\n",
        "            for word in current_words:\n",
        "                word = word.strip()\n",
        "                # 空の単語はスキップ\n",
        "                if not word:\n",
        "                    continue\n",
        "                # 削除対象のタグかチェック\n",
        "                if any(tag == word.lower() for tag in tags_to_remove):\n",
        "                    continue\n",
        "                # まだ追加されていない単語のみ追加（重複排除）\n",
        "                if word not in words:\n",
        "                    words.append(word)\n",
        "\n",
        "            # カンマで結合して返す\n",
        "            return ', '.join(words)\n",
        "\n",
        "        if \"<prompt>\" in model_response:\n",
        "            if \"</prompt>\" in model_response:\n",
        "                prompt_text = model_response.split(\"<prompt>\")[1].split(\"</prompt>\")[0].strip()\n",
        "            else:\n",
        "                prompt_text = model_response.split(\"<prompt>\")[1].strip()\n",
        "\n",
        "            prompt_text = clean_prompt_text(prompt_text)\n",
        "        else:\n",
        "            prompt_text = f\"1girl, {character_name}, {series_name}, anime style, highres\"\n",
        "\n",
        "        prompt_text = prompt_text + f\", {category}\"\n",
        "\n",
        "        logger.info(f\"Successfully generated prompt from text\")\n",
        "\n",
        "        # モデルのアンロード\n",
        "        unload_prompt_model()\n",
        "\n",
        "        return thinking, prompt_text\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating prompt: {str(e)}\")\n",
        "        # エラー時のフォールバック\n",
        "        return f\"エラーが発生しました: {str(e)}\", f\"1girl, {character_name}, {series_name}, anime style, highres\"\n",
        "    finally:\n",
        "        # 確実にモデルをアンロード\n",
        "        unload_prompt_model()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yJh_BpPOmrCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (3)Module for image generation/画像生成のためのモジュール\n",
        "# ======== セル3: 画像生成のためのモジュール ========\n",
        "# グローバル変数としてパイプラインを定義\n",
        "pipe = None\n",
        "vae = None\n",
        "\n",
        "def load_image_model():\n",
        "    \"\"\"画像生成モデルをロードする関数\"\"\"\n",
        "    global pipe, vae\n",
        "\n",
        "    # メモリ管理\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    # デバイス設定\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info(f\"Using device: {device} for image model\")\n",
        "\n",
        "    # スタイル辞書の作成\n",
        "    styles_dict = get_style_dict()\n",
        "\n",
        "    logger.info(f\"Loading VAE from {MODEL}\")\n",
        "    # VAEを明示的にロード\n",
        "    vae = AutoencoderKL.from_pretrained(\n",
        "        MODEL,\n",
        "        subfolder=\"vae\",\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "    # パイプラインにVAEを渡す\n",
        "    pipe = load_pipeline(MODEL, device, vae=vae)\n",
        "\n",
        "    logger.info(\"Image generation model loaded successfully\")\n",
        "    return pipe\n",
        "\n",
        "def unload_image_model():\n",
        "    \"\"\"画像生成モデルをアンロードする関数\"\"\"\n",
        "    global pipe, vae\n",
        "\n",
        "    if pipe is not None:\n",
        "        del pipe\n",
        "        pipe = None\n",
        "\n",
        "    if vae is not None:\n",
        "        del vae\n",
        "        vae = None\n",
        "\n",
        "    # メモリの解放\n",
        "    free_memory()\n",
        "\n",
        "    logger.info(\"Image generation model unloaded\")\n",
        "\n",
        "def generate_image(\n",
        "    prompt: str,\n",
        "    negative_prompt: str = DEFAULT_NEGATIVE_PROMPT,\n",
        "    seed: int = -1,\n",
        "    width: int = 832,\n",
        "    height: int = 1216,\n",
        "    guidance_scale: float = 5.0,\n",
        "    num_inference_steps: int = 28,\n",
        "    sampler: str = \"Euler a\",\n",
        "    style_selector: str = \"(None)\",\n",
        "    add_quality_tags: bool = True,\n",
        ") -> Tuple[str, Dict]:\n",
        "    \"\"\"与えられたパラメータに基づいて画像を生成する\"\"\"\n",
        "    global pipe\n",
        "\n",
        "    # パイプラインがロードされていない場合はロード\n",
        "    if pipe is None:\n",
        "        pipe = load_image_model()\n",
        "\n",
        "    start_time = time.time()\n",
        "    backup_scheduler = None\n",
        "    styles_dict = get_style_dict()\n",
        "\n",
        "    try:\n",
        "        # メモリ管理\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        # 入力の検証\n",
        "        if not prompt or prompt.isspace():\n",
        "            raise ValueError(\"プロンプトが空です\")\n",
        "\n",
        "        # 画像サイズのチェック\n",
        "        if not (MIN_IMAGE_SIZE <= width <= MAX_IMAGE_SIZE):\n",
        "            raise ValueError(f\"幅は{MIN_IMAGE_SIZE}から{MAX_IMAGE_SIZE}の間である必要があります\")\n",
        "        if not (MIN_IMAGE_SIZE <= height <= MAX_IMAGE_SIZE):\n",
        "            raise ValueError(f\"高さは{MIN_IMAGE_SIZE}から{MAX_IMAGE_SIZE}の間である必要があります\")\n",
        "\n",
        "        # シードの設定\n",
        "        if seed == -1:  # シードが指定されていない場合はランダム\n",
        "            seed = random.randint(0, MAX_SEED)\n",
        "        generator = seed_everything(seed)\n",
        "\n",
        "        # 画像サイズの前処理\n",
        "        width, height = preprocess_image_dimensions(width, height)\n",
        "\n",
        "        # プロンプト処理\n",
        "        if add_quality_tags:\n",
        "            prompt = \"{prompt}, masterpiece, high score, great score, absurdres\".format(prompt=prompt)\n",
        "\n",
        "        prompt, negative_prompt = preprocess_prompt(\n",
        "            styles_dict, style_selector, prompt, negative_prompt\n",
        "        )\n",
        "\n",
        "        # スケジューラの設定\n",
        "        backup_scheduler = pipe.scheduler\n",
        "        pipe.scheduler = get_scheduler(pipe.scheduler.config, sampler)\n",
        "\n",
        "        # メタデータ準備\n",
        "        metadata = {\n",
        "            \"prompt\": prompt,\n",
        "            \"negative_prompt\": negative_prompt,\n",
        "            \"resolution\": f\"{width} x {height}\",\n",
        "            \"guidance_scale\": guidance_scale,\n",
        "            \"num_inference_steps\": num_inference_steps,\n",
        "            \"style_preset\": style_selector,\n",
        "            \"seed\": seed,\n",
        "            \"sampler\": sampler,\n",
        "            \"Model\": \"Animagine XL 4.0\",\n",
        "        }\n",
        "\n",
        "        logger.info(f\"Starting generation with parameters: {json.dumps(metadata, indent=4)}\")\n",
        "\n",
        "        # 画像生成\n",
        "        images = pipe(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            width=width,\n",
        "            height=height,\n",
        "            guidance_scale=guidance_scale,\n",
        "            num_inference_steps=num_inference_steps,\n",
        "            generator=generator,\n",
        "            output_type=\"pil\",\n",
        "        ).images\n",
        "\n",
        "        # 画像保存\n",
        "        image_path = \"\"\n",
        "        if images:\n",
        "            image = images[0]  # 最初の画像を保存\n",
        "            image_path = save_image(image, metadata, OUTPUT_DIR)\n",
        "            logger.info(f\"Image saved as {image_path}\")\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        logger.info(f\"Generation completed successfully in {generation_time:.2f} seconds\")\n",
        "        metadata[\"generation_time\"] = f\"{generation_time:.2f}s\"\n",
        "\n",
        "        return image_path, metadata\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(\"Unexpected error during generation\")\n",
        "        raise ValueError(f\"Generation failed: {str(e)}\")\n",
        "    finally:\n",
        "        # クリーンアップ\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        if backup_scheduler is not None and pipe is not None:\n",
        "            pipe.scheduler = backup_scheduler\n",
        "\n",
        "        # 画像生成後にモデルをアンロード\n",
        "        unload_image_model()\n",
        "\n",
        "\n",
        "def regenerate_image_only(custom_prompt=None):\n",
        "    try:\n",
        "        # 設定情報を取得\n",
        "        import IPython\n",
        "        user_ns = IPython.get_ipython().user_ns\n",
        "\n",
        "        # 保存されたプロンプトを使用するか、新しいプロンプトを使用するか\n",
        "        if custom_prompt:\n",
        "            # カスタムプロンプトが提供された場合はそれを使用\n",
        "            prompt = custom_prompt\n",
        "            print(f\"カスタムプロンプトを使用します:\\n{prompt}\")\n",
        "        else:\n",
        "            # 以前に生成されたプロンプトを使用\n",
        "            if 'last_generated_prompt' in user_ns:\n",
        "                prompt = user_ns['last_generated_prompt']\n",
        "                print(f\"保存されたプロンプトを使用します:\\n{prompt}\")\n",
        "            else:\n",
        "                print(\"保存されたプロンプトが見つかりません。プロンプトを指定してください。\")\n",
        "                return\n",
        "\n",
        "        # スタイル設定を取得\n",
        "        style_name = user_ns.get('image_style', \"(None)\")\n",
        "        negative_prompt = user_ns.get('DEFAULT_NEGATIVE_PROMPT', \"\")\n",
        "\n",
        "        # 画像生成に必要な関数がロード済みか確認\n",
        "        if 'generate_image' not in user_ns:\n",
        "            print(\"画像生成関数がロードされていません。先に画像生成処理を実行してください。\")\n",
        "            return\n",
        "\n",
        "        # モデルが既にアンロードされている場合は再ロード\n",
        "        if 'unload_image_model' in user_ns:\n",
        "            print(\"画像生成モデルをロードしています...\")\n",
        "            unload_image_model = user_ns['unload_image_model']\n",
        "            unload_image_model()\n",
        "\n",
        "        # 画像生成\n",
        "        generate_image = user_ns['generate_image']\n",
        "        print(f\"プロンプト '{prompt}' で画像を生成しています...\")\n",
        "\n",
        "        # 最後に使用したプロンプトを更新\n",
        "        user_ns['last_generated_prompt'] = prompt\n",
        "\n",
        "        # 画像を生成\n",
        "        image_path, image_metadata = generate_image(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            seed=-1,  # ランダムシード\n",
        "            width=832,\n",
        "            height=1216,\n",
        "            guidance_scale=5.0,\n",
        "            num_inference_steps=28,\n",
        "            style_selector=style_name\n",
        "        )\n",
        "\n",
        "        # 結果表示\n",
        "        from IPython.display import display, Image\n",
        "        print(f\"画像が生成されました: {image_path}\")\n",
        "        display(Image(image_path))\n",
        "\n",
        "        return image_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"画像生成中にエラーが発生しました: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# プロンプトをロードしてフォームに表示する関数\n",
        "def load_last_prompt():\n",
        "    import IPython\n",
        "    user_ns = IPython.get_ipython().user_ns\n",
        "    if 'last_generated_prompt' in user_ns:\n",
        "        prompt = user_ns['last_generated_prompt']\n",
        "        return prompt\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# カスタムプロンプトで画像を生成する関数\n",
        "def generate_with_custom_prompt(prompt):\n",
        "    if not prompt or prompt.strip() == \"\":\n",
        "        print(\"プロンプトが空です。生成を中止します。\")\n",
        "        return\n",
        "    return regenerate_image_only(prompt)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cmyXBMKsnUkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (4)Main execution function/メイン実行関数\n",
        "def main(\n",
        "    novel_text: str = None,\n",
        "    series_name: str = \"original\",\n",
        "    character_name: str = \"original character\",\n",
        "    category: str = \"general\",\n",
        "    style_name: str = \"(None)\",\n",
        "    negative_prompt: str = DEFAULT_NEGATIVE_PROMPT,\n",
        "    width: int = 832,\n",
        "    height: int = 1216,\n",
        "    seed: int = -1,\n",
        "    guidance_scale: float = 5.0,\n",
        "    steps: int = 28,\n",
        "    prompt_only: bool = False\n",
        "):\n",
        "    \"\"\"\n",
        "    メイン実行関数:\n",
        "    1. 小説テキストからプロンプトを生成\n",
        "    2. 必要に応じて画像を生成\n",
        "\n",
        "    引数:\n",
        "        novel_text: 小説テキスト\n",
        "        series_name: シリーズ名（例: \"original\", \"touhou\"）\n",
        "        character_name: キャラクター名（例: \"original character\", \"hakurei reimu\"）\n",
        "        category: カテゴリー（例: \"general\", \"sensitive\"）\n",
        "        style_name: スタイル名（例: \"(None)\", \"Anim4gine\", \"Pixel art\"）\n",
        "        negative_prompt: ネガティブプロンプト\n",
        "        width: 画像の幅\n",
        "        height: 画像の高さ\n",
        "        seed: 生成シード値（-1でランダム）\n",
        "        guidance_scale: ガイダンススケール値\n",
        "        steps: 推論ステップ数\n",
        "        prompt_only: Trueの場合、プロンプト生成のみ行い画像は生成しない\n",
        "\n",
        "    戻り値:\n",
        "        生成されたプロンプト、思考過程、生成された画像のパス（または空文字）、メタデータ\n",
        "    \"\"\"\n",
        "    # 結果を格納する変数の初期化\n",
        "    thinking = \"\"\n",
        "    generated_prompt = \"\"\n",
        "    image_path = \"\"\n",
        "    metadata = {}\n",
        "\n",
        "    try:\n",
        "        # ステップ1: プロンプト生成\n",
        "        if novel_text:\n",
        "            logger.info(f\"Generating prompt for novel text with series={series_name}, character={character_name}, category={category}\")\n",
        "            thinking, generated_prompt = generate_prompt(novel_text, series_name, character_name, category)\n",
        "            logger.info(f\"Generated prompt: {generated_prompt}\")\n",
        "\n",
        "            metadata[\"prompt_generation\"] = {\n",
        "                \"series\": series_name,\n",
        "                \"character\": character_name,\n",
        "                \"category\": category,\n",
        "                \"thinking\": thinking[:300] + \"...\" if len(thinking) > 300 else thinking\n",
        "            }\n",
        "        else:\n",
        "            # 小説テキストがない場合は直接生成\n",
        "            generated_prompt = f\"1girl, {character_name}, {series_name}, anime style, highres, {category}\"\n",
        "            logger.info(f\"No novel text provided. Using default prompt: {generated_prompt}\")\n",
        "\n",
        "        logger.info(f\"make text prompt done\")\n",
        "\n",
        "        # ステップ2: 画像生成（prompt_onlyがFalseの場合）\n",
        "        if not prompt_only and generated_prompt:\n",
        "            logger.info(f\"Generating image with prompt: {generated_prompt}\")\n",
        "            image_path, image_metadata = generate_image(\n",
        "                prompt=generated_prompt,\n",
        "                negative_prompt=negative_prompt,\n",
        "                seed=seed,\n",
        "                width=width,\n",
        "                height=height,\n",
        "                guidance_scale=guidance_scale,\n",
        "                num_inference_steps=steps,\n",
        "                style_selector=style_name\n",
        "            )\n",
        "\n",
        "            metadata.update(image_metadata)\n",
        "            logger.info(f\"Image generated and saved to: {image_path}\")\n",
        "\n",
        "        # 戻り値の構築\n",
        "        if prompt_only:\n",
        "            result_message = f\"プロンプト生成が完了しました。\\n\\n思考過程:\\n{thinking}\\n\\n生成プロンプト:\\n{generated_prompt}\"\n",
        "        else:\n",
        "            result_message = f\"プロンプト生成と画像生成が完了しました。\\n\\n思考過程:\\n{thinking}\\n\\n生成プロンプト:\\n{generated_prompt}\\n\\n画像パス:\\n{image_path}\"\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"message\": result_message,\n",
        "            \"thinking\": thinking,\n",
        "            \"prompt\": generated_prompt,\n",
        "            \"image_path\": image_path,\n",
        "            \"metadata\": metadata\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"実行中にエラーが発生しました: {str(e)}\"\n",
        "        logger.exception(error_message)\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"message\": error_message,\n",
        "            \"thinking\": thinking,\n",
        "            \"prompt\": generated_prompt,\n",
        "            \"image_path\": image_path,\n",
        "            \"metadata\": metadata\n",
        "        }\n",
        "\n",
        "def run_in_colab(novel_text, series_name, character_name, category, style_name=\"(None)\", prompt_only=False):\n",
        "    \"\"\"Colab用のシンプルな実行関数 - プロンプト保存機能付き\"\"\"\n",
        "    from IPython.display import display, Image\n",
        "    import IPython\n",
        "\n",
        "    # 既存の画像モデルをアンロード\n",
        "    if 'unload_image_model' in IPython.get_ipython().user_ns:\n",
        "        unload_image_model = IPython.get_ipython().user_ns['unload_image_model']\n",
        "        unload_image_model()\n",
        "\n",
        "    # メイン処理実行\n",
        "    result = main(\n",
        "        novel_text=novel_text,\n",
        "        series_name=series_name,\n",
        "        character_name=character_name,\n",
        "        category=category,\n",
        "        style_name=style_name,\n",
        "        prompt_only=prompt_only\n",
        "    )\n",
        "\n",
        "    if result[\"success\"]:\n",
        "        print(\"■ Thought Process/思考過程:\")\n",
        "        print(result[\"thinking\"])\n",
        "        print(\"\\n■ Generate prompt/生成プロンプト:\")\n",
        "        print(result[\"prompt\"])\n",
        "\n",
        "        # 生成したプロンプトをグローバル変数として保存\n",
        "        IPython.get_ipython().user_ns['last_generated_prompt'] = result[\"prompt\"]\n",
        "\n",
        "        if result[\"image_path\"] and not prompt_only:\n",
        "            print(\"\\n■ Generate Image/生成画像:\")\n",
        "            display(Image(result[\"image_path\"]))\n",
        "    else:\n",
        "        print(f\"エラー: {result['message']}\")\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8JvR83EDnfqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#@title (5)Download two models/２つのモデルのダウンロード(14GB)\n",
        "\n",
        "load_image_model()\n",
        "unload_image_model()\n",
        "load_prompt_model()"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "3y-GJCIA2w95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. FanFic Illustrator\n",
        "\n",
        "#### (1)Fan fiction settings/二次創作の設定\n",
        "After running the cell, select the novel category, series, character name, and image style  \n",
        "セルを実行した後、小説のカテゴリ、シリーズ、キャラクター名、画像スタイルを選択してください\n",
        "#### (2)Entering your fan novels/ファンノベルの入力\n",
        "After running the cell, copy your creative writing and press \"Save\".  \n",
        "セルを実行した後、あなたの創作文をコピーし、「Save」を押してください  \n",
        "#### (3)Creating illustrations for your novels/小説用挿絵の作成\n",
        "Running the cell will create a prompt and an illustration.  \n",
        "セルを実行するとプロンプトと挿絵が作成されます\n",
        "#### (4)GPU Memory Management and Image Regeneration Controls/GPUメモリの強制解放と画像の再生成\n",
        "After you run the cell, you can manually edit the prompt or recreate the image.\n",
        "\n",
        " セルを実行した後、プロンプトの手動編集や画像の再作成が可能です"
      ],
      "metadata": {
        "id": "Fh8DAKfM3xE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    #@title (1)Fan fiction settings/二次創作の設定\n",
        "    category = 'general|一般向け' #@param [\"general|一般向け\", \"sensitive|多少のセクシー要素を含む\"]\n",
        "    series_name = 'virtual_youtuber|Vtuber' #@param [\"original|特定の原作なし\", \"vocaloid|ボーカロイド\", \"kantai collection|艦隊これくしょん\", \"touken ranbu|刀剣乱舞\", \"virtual_youtuber|Vtuber\"]\n",
        "    character_name = 'dokibird (vtuber)' #@param [\"original character|オリジナルキャラクター\", \"kaga (kancolle)|加賀（艦これ）\", \"shimakaze (kancolle)|島風（艦これ）\", \"hibiki (kancolle)|響（艦これ）\", \"shigure (kancolle)|時雨（艦これ）\", \"kongou (kancolle)|金剛（艦これ）\", \"hatsune miku|初音ミク\", \"kagamine rin|鏡音リン\", \"kagamine len|鏡音レン\", \"megurine luka|巡音ルカ\", \"yuzuki yukari|結月ゆかり\", \"shigure ui (vtuber)\", \"dokibird (vtuber)\", \"mikazuki munechika|三日月宗近\", \"kashuu kiyomitsu|加州清光\", \"yamato-no-kami yasusada|大和守安定\", \"tsurumaru kuninaga|鶴丸国永\", \"namazuo toushirou|鯰尾藤四郎\"]\n",
        "    image_style = '(None)' #@param [\"(None)\", \"Anim4gine\", \"Painting\", \"Pixel art\", \"1980s\", \"1990s\", \"2000s\", \"Toon\", \"Lineart\", \"Art Nouveau\", \"Western Comics\", \"3D\", \"Realistic\", \"Neonpunk\"]\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LfYTVtZr2trR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (2) Entering your fan novels/ファンノベルの入力(Japanese/English/other languages text ok)\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "textarea_html = \"\"\"\n",
        "<textarea id=\"novel_text\" style=\"width: 100%; height: 700px; padding: 10px; font-family: Arial; font-size: 14px;\"\n",
        "placeholder=\"Entering your fan novels and push Save button/ここに小説のテキストを貼り付けてSaveボタンを押してください...\"></textarea>\n",
        "<button onclick=\"saveText()\">Save</button>\n",
        "<button onclick=\"displayLog()\">Display as Log</button>\n",
        "<div id=\"status\"></div>\n",
        "\n",
        "<script>\n",
        "function saveText() {\n",
        "  var text = document.getElementById('novel_text').value;\n",
        "  // Colabの変数に値を保存\n",
        "  google.colab.kernel.invokeFunction('notebook.updateVariable', ['novel_content', text], {});\n",
        "  document.getElementById('status').innerHTML = \"Saved text!\";\n",
        "}\n",
        "\n",
        "function displayLog() {\n",
        "  var text = document.getElementById('novel_text').value;\n",
        "  // テキストをログとして表示する関数を呼び出す\n",
        "  google.colab.kernel.invokeFunction('notebook.displayAsLog', ['novel_content', text], {});\n",
        "  document.getElementById('status').innerHTML = \"Displayed as log!\";\n",
        "}\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(textarea_html))\n",
        "\n",
        "# 変数を受け取るための関数を登録\n",
        "from google.colab import output\n",
        "import IPython\n",
        "\n",
        "novel_content = \"\"\n",
        "\n",
        "def update_variable(name, value):\n",
        "    global novel_content\n",
        "    if name == 'novel_content':\n",
        "        novel_content = value\n",
        "        print(f\"テキストを保存しました（{len(value)}文字）\")\n",
        "\n",
        "def display_as_log(name, value):\n",
        "    # 前のセルで設定された値を取得\n",
        "    try:\n",
        "        # 他のセルで定義された変数を取得\n",
        "        # IPython.get_ipython().user_ns から変数を取得\n",
        "        user_ns = IPython.get_ipython().user_ns\n",
        "        category = user_ns.get('category', 'Not set')\n",
        "        series_name = user_ns.get('series_name', 'Not set')\n",
        "        character_name = user_ns.get('character_name', 'Not set')\n",
        "        image_style = user_ns.get('image_style', 'Not set')\n",
        "\n",
        "        # 設定とテキストプレビューを表示\n",
        "        print(\"## 二次創作設定とテキストログ\")\n",
        "        print(\"### 設定情報\")\n",
        "        print(f\"- **カテゴリ**: {category}\")\n",
        "        print(f\"- **シリーズ名**: {series_name}\")\n",
        "        print(f\"- **キャラクター名**: {character_name}\")\n",
        "        print(f\"- **イメージスタイル**: {image_style}\")\n",
        "\n",
        "        print(\"\\n### テキストプレビュー（最初の500文字）\")\n",
        "        print(\"```\")\n",
        "        # 最初の500文字を表示（または全文が500文字未満の場合は全文）\n",
        "        preview = value[:500]\n",
        "        if len(value) > 500:\n",
        "            preview += \"...\"\n",
        "        print(preview)\n",
        "        print(\"```\")\n",
        "\n",
        "        print(f\"\\n全文字数: {len(value)}文字\")\n",
        "\n",
        "        # 変数にも保存\n",
        "        global novel_content\n",
        "        novel_content = value\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"エラーが発生しました: {e}\")\n",
        "        print(\"テキストのみ表示します:\")\n",
        "        print(\"```\")\n",
        "        preview = value[:500]\n",
        "        if len(value) > 500:\n",
        "            preview += \"...\"\n",
        "        print(preview)\n",
        "        print(\"```\")\n",
        "\n",
        "output.register_callback('notebook.updateVariable', update_variable)\n",
        "output.register_callback('notebook.displayAsLog', display_as_log)"
      ],
      "metadata": {
        "id": "P-TvRTulIMp0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (3) Creating illustrations for your novels/小説用挿絵の作成\n",
        "result = run_in_colab(\n",
        "    novel_text=novel_content,\n",
        "    series_name=series_name.split('|')[0],\n",
        "    character_name=character_name.split('|')[0],\n",
        "    category=category.split('|')[0],\n",
        "    style_name=image_style\n",
        ")\n",
        "\n",
        "#time.sleep(10)\n",
        "#force_gpu_memory_release()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cZrUAm2enn_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (4)GPU Memory Management and Image Regeneration Controls/GPUメモリの強制解放と画像の再生成\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "# 最後のプロンプトを取得してUIの初期表示に使用\n",
        "last_prompt = load_last_prompt()\n",
        "\n",
        "# UIボタン表示\n",
        "html_content = f\"\"\"\n",
        "<div style=\"padding: 10px; margin: 10px 0; background-color: #f8f9fa; border-radius: 5px;\">\n",
        "  <h3 style=\"margin-top: 0;\">GPU Memory & Image regeneration control/GPUメモリ & 画像再生成コントロール</h3>\n",
        "\n",
        "  <div style=\"margin-bottom: 15px;\">\n",
        "    <h4 style=\"margin-top: 10px;\">prompt edit & regenarate image/プロンプト編集 & 画像再生成</h4>\n",
        "    <textarea id=\"customPrompt\" style=\"width: 100%; height: 100px; margin-bottom: 10px; padding: 8px; font-family: monospace; font-size: 14px;\">{last_prompt}</textarea>\n",
        "    <button onclick=\"regenerateWithCustomPrompt()\" style=\"background-color: #007bff; color: white; padding: 8px 12px; border: none; border-radius: 4px; cursor: pointer;\">\n",
        "      Regenerated image using edited prompt/編集したプロンプトで画像生成\n",
        "    </button>\n",
        "    <button onclick=\"loadLastPrompt()\" style=\"background-color: #6c757d; color: white; padding: 8px 12px; border: none; border-radius: 4px; margin-left: 10px; cursor: pointer;\">\n",
        "      load last prompt/最後のプロンプトを読み込む\n",
        "    </button>\n",
        "    <p style=\"font-size: 12px; color: #6c757d;\">※you can edit prompt directly and make image again./プロンプトを編集して画像を再生成できます</p>\n",
        "  </div>\n",
        "\n",
        "  <div style=\"margin-bottom: 15px;\">\n",
        "    <button onclick=\"releaseGPUMemory()\" style=\"background-color: #dc3545; color: white; padding: 8px 12px; border: none; border-radius: 4px; cursor: pointer;\">\n",
        "      Force GPU memory release with risk/GPUメモリ強制解放 (⚠️リスクあり)\n",
        "    </button>\n",
        "    <p style=\"font-size: 12px; color: #6c757d;\">※If you recreate the image multiple times, the GPU memory may become full. This button is used in such cases. But maybe runtime become unstable.<br>\n",
        "何度も再作成しているとGPUメモリが一杯になってしまう時があります。その時に使うボタンです。しかし実行すると動作が不安定になる可能性があります</p>\n",
        "  </div>\n",
        "\n",
        "</div>\n",
        "<script>\n",
        "function releaseGPUMemory() {{\n",
        "  const button = document.querySelector(\"button\");\n",
        "  button.disabled = true;\n",
        "  button.textContent = \"releasing/解放処理中...\";\n",
        "\n",
        "  google.colab.kernel.invokeFunction('notebook.forceGPUMemoryRelease', [], {{}})\n",
        "    .then(function() {{\n",
        "      button.disabled = false;\n",
        "      button.textContent = \"Force GPU memory release with risk./GPUメモリ強制解放 (⚠️リスクあり)\";\n",
        "    }})\n",
        "    .catch(function(error) {{\n",
        "      console.error('Error:', error);\n",
        "      button.disabled = false;\n",
        "      button.textContent = \"/Force GPU memory release error./GPUメモリ強制解放 (⚠️エラー発生)\";\n",
        "    }});\n",
        "}}\n",
        "\n",
        "function regenerateWithCustomPrompt() {{\n",
        "  const textarea = document.getElementById('customPrompt');\n",
        "  const prompt = textarea.value;\n",
        "  const button = document.querySelectorAll(\"button\")[1];\n",
        "\n",
        "  button.disabled = true;\n",
        "  button.textContent = \"generate image/画像生成中...\";\n",
        "\n",
        "  google.colab.kernel.invokeFunction('notebook.generateWithCustomPrompt', [prompt], {{}})\n",
        "    .then(function() {{\n",
        "      button.disabled = false;\n",
        "      button.textContent = \"Regenerated image using edited prompt/編集したプロンプトで画像生成\";\n",
        "    }})\n",
        "    .catch(function(error) {{\n",
        "      console.error('Error:', error);\n",
        "      button.disabled = false;\n",
        "      button.textContent = \"Regenerated image using edited prompt error/編集したプロンプトで画像生成 (⚠️エラー発生)\";\n",
        "    }});\n",
        "}}\n",
        "\n",
        "function loadLastPrompt() {{\n",
        "  google.colab.kernel.invokeFunction('notebook.loadLastPrompt', [], {{}})\n",
        "    .then(function(response) {{\n",
        "      const prompt = response.data['application/json'].result;\n",
        "      document.getElementById('customPrompt').value = prompt;\n",
        "    }})\n",
        "    .catch(function(error) {{\n",
        "      console.error('Error:', error);\n",
        "    }});\n",
        "}}\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# コールバック関数の登録\n",
        "from google.colab import output\n",
        "\n",
        "output.register_callback('notebook.forceGPUMemoryRelease', force_gpu_memory_release)\n",
        "output.register_callback('notebook.generateWithCustomPrompt', generate_with_custom_prompt)\n",
        "output.register_callback('notebook.loadLastPrompt', load_last_prompt)\n",
        "\n",
        "# UI表示\n",
        "display(HTML(html_content))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NocLpdwcYyJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acknowledgements/謝辞\n",
        "We would like to thank the following people for providing related models/methods/tools.  \n",
        "以下の関連モデル/手法/ツールを提供してくださった皆さんに感謝します。  \n",
        "- Image Generation Model and style prompt [cagliostrolab/animagine-xl-4.0](https://huggingface.co/cagliostrolab/animagine-xl-4.0)\n",
        "- Sample novel text [Coolier - 新生・東方創想話/博麗ベニズワイガニ](https://coolier.net/sosowa/ssw_l/193/1390706258)\n",
        "- Base Model: [Qwen/Qwen2.5-3B-Instruct](https://huggingface.co/Qwen/Qwen2.5-3B-Instruct)\n",
        "- Training Methods: (DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models)[https://arxiv.org/abs/2402.03300]\n",
        "- Traing script: [Unsloth](https://huggingface.co/unsloth).\n",
        "- [Danbooru tags](https://danbooru.donmai.us/wiki_pages/tag_groups) for tagging.\n",
        "- [Huggingface](https://huggingface.co/) for storage."
      ],
      "metadata": {
        "id": "G19mXDdBLeon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Developer/開発\n",
        "\n",
        "- **Developed by:** dahara1@webbigdata\n",
        "- **Model type:** text generation\n",
        "- **Language(s) (NLP):** Japanese, English\n",
        "- **model :** [webbigdata/FanFic-Illustrator](https://huggingface.co/webbigdata/FanFic-Illustrator)"
      ],
      "metadata": {
        "id": "0kZ8Jo4s6S01"
      }
    }
  ]
}