{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/webbigdata-jp/python_sample/blob/main/gemma_2_2b_jpn_it_translate_gguf_Free_Colab_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tCLTsfT_qgA"
      },
      "source": [
        "gemma-2-2b-jpn-it-translate-ggufは日英・英日に特化した機械翻訳モデル[webbigdata/gemma-2-2b-jpn-it-translate-gguf](https://huggingface.co/webbigdata/gemma-2-2b-jpn-it-translate-gguf)をgpuがなくても動くように変換したサンプルです。  このColabのサンプルに従うと、GPUがないMacやColabでも動かす事ができます。    \n",
        "\n",
        "gemma-2-2b-jpn-it-translate-gguf is a sample that converts a machine translation model[webbigdata/gemma-2-2b-jpn-it-translate-gguf](https://huggingface.co/webbigdata/gemma-2-2b-jpn-it-translate-gguf) specialized for Japanese-English and English-Japanese to run without a gpu.  If you follow this Colab sample, you can run it on a Mac or Colab without a GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "llama.cppを使うと、様々な量子化手法でファイルのサイズを小さくする事が出来ます。本サンプルでは4種類のみを扱います。小さいサイズのモデルは、少ないメモリで高速に動作させることができますが、モデルの性能も低下します。4ビット(q4_k_m)くらいがバランスが良いと言われていますが、本サンプルコードでは特定の文章を全モデルで翻訳し、どのモデルが貴方の作業に適切かを確認できるようにしたものです。gguf版はパラメーターの調整をしないと幻覚が増えます。  \n",
        "\n",
        "Although llama.cpp can be used to reduce the size of the file with various quantization methods, this sample deals with only 4 types. Smaller models can run faster with less memory, but the performance of the models is also reduced. 4 bits (q4_k_m) is said to be a good balance, but this sample code translates a particular sentence with all models so that you can see which model is appropriate for your work. This sample code translates a specific sentence across all models so that you can see which model is appropriate for your work.The GGUF version will have more hallucinations if you don't adjust the parameters.  \n",
        "\n",
        "- gemma-2-2b-jpn-it-translate-IQ3_XXS.gguf 1.18GB\n",
        "- gemma-2-2b-jpn-it-translate-Q4_K_L.gguf 1.85GB\n",
        "\n",
        "\n",
        "必要に応じて以下のパラメーターを調整してください  \n",
        "\n",
        "- 温度（--temp）: この値を下げると、モデルがより確信度の高い（つまり、より一般的な）単語を選択する傾向が強くなります。\n",
        "- トップP（--top_p）: この値をさらに低く設定することで、モデルが考慮する単語の範囲を狭め、より一貫性のあるテキストを生成するようになります。\n",
        "- 生成する単語数（-n）: この値を減らすことで、モデルが生成するテキストの長さを短くし、不要な追加テキストの生成を防ぐことができます。-1 = 無限大、-2 = 文脈が満たされるまで。\n",
        "\n",
        "以下はllama.cppの作者(ggerganov)による推奨パラメーターです\n",
        "\n",
        "- -e (改行\\nをエスケープ)\n",
        "- --temp 0 (最も確率の高いトークンのみを選択)\n",
        "- --repeat-penalty 1.0 (繰り返しペナルティをオフ)\n",
        "\n",
        "Adjust the following parameters as needed  \n",
        "- Temperature (--temp): Lowering this value will make the model more likely to select more confident (i.e., more common) words.\n",
        "- Top P (--top_p): Setting this value even lower will narrow the range of words considered by the model and produce more consistent text.\n",
        "- Number of words to generate (-n): Reducing this value will shorten the length of text generated by the model and prevent the generation of unnecessary additional text. -1 = infinity(default), -2 = until context filled.\n",
        "\n",
        "The following are the recommended parameters by the author of llama.cpp(ggerganov)\n",
        "- -e (escape newlines (\\n))\n",
        "- --temp 0(pick most probable tokens)\n",
        "- --repeat-penalty 1.0(disable repetition penalty (it's never a good idea to have this with instruction tuned models)\n",
        "\n",
        "\n",
        "上段メニューより「ランタイム」→「全てのセルを実行」で実行できます。  \n",
        "You can run this by selecting \"Runtime\" > \"Run All Cells\" from the top menu.  "
      ],
      "metadata": {
        "id": "EO7RPRM9vaKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "改行を含む複数の文章を一括して翻訳する事はできません。文章は一文ずつ、チャット形式で入力してください。以下の例ではプロンプトテンプレートを手動で設定していますが、[gemma-2-2b-jpn-it-translate-gguf page](https://huggingface.co/webbigdata/gemma-2-2b-jpn-it-translate-gguf)のサンプルなどを参考にapply_chat_templateを使って変換する事をお勧めします。  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "It is not possible to translate multiple sentences including line breaks at once. Please enter each sentence in chat format. In the following example, the prompt template is set manually, but we recommend using apply_chat_template to convert the text, as shown in the sample on [gemma-2-2b-jpn-it-translate-gguf page](https://huggingface.co/webbigdata/gemma-2-2b-jpn-it-translate-gguf).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G_b8TagO3uA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "os.environ['TRANSLATE_TEMPLATE_Ja'] = \"\"\"<start_of_turn>user\n",
        "You are a highly skilled professional Japanese-English and English-Japanese translator. Translate the given text accurately, taking into account the context and specific instructions provided. Steps may include hints enclosed in square brackets [] with the key and value separated by a colon:. Only when the subject is specified in the Japanese sentence, the subject will be added when translating into English. If no additional instructions or context are provided, use your expertise to consider what the most appropriate context is and provide a natural translation that aligns with that context. When translating, strive to faithfully reflect the meaning and tone of the original text, pay attention to cultural nuances and differences in language usage, and ensure that the translation is grammatically correct and easy to read. After completing the translation, review it once more to check for errors or unnatural expressions. For technical terms and proper nouns, either leave them in the original language or use appropriate translations as necessary. Take a deep breath, calm down, and start translating.\n",
        "\n",
        "Translate Japanese to English.\n",
        "When translating, please use the following hints:\n",
        "[writeing_style: web-fiction]\n",
        "[羂索: Kenjyaku]\n",
        "<start_of_turn>model\n",
        "OK<end_of_turn>\n",
        "<start_of_turn>user\n",
        "羂索 （美しい、本気の土下座だ…私がこの域に達したのは20代後半……)<end_of_turn>\n",
        "<start_of_turn>model\n",
        "\"\"\"\n",
        "\n",
        "os.environ['TRANSLATE_TEMPLATE_En'] = \"\"\"<start_of_turn>user\n",
        "You are a highly skilled professional Japanese-English and English-Japanese translator. Translate the given text accurately, taking into account the context and specific instructions provided. Steps may include hints enclosed in square brackets [] with the key and value separated by a colon:. Only when the subject is specified in the Japanese sentence, the subject will be added when translating into English. If no additional instructions or context are provided, use your expertise to consider what the most appropriate context is and provide a natural translation that aligns with that context. When translating, strive to faithfully reflect the meaning and tone of the original text, pay attention to cultural nuances and differences in language usage, and ensure that the translation is grammatically correct and easy to read. After completing the translation, review it once more to check for errors or unnatural expressions. For technical terms and proper nouns, either leave them in the original language or use appropriate translations as necessary. Take a deep breath, calm down, and start translating.\n",
        "\n",
        "Translate English to Japanese.\n",
        "When translating, please use the following hints:\n",
        "[writing_style: casual, nsfw]\n",
        "[Geoffrey Hinton: ジェフェリー・ヒントン]\n",
        "[Sam Altman: サム・アルトマン]\n",
        "[Ilya Sutskever: イリヤ・サツケバー]\n",
        "<start_of_turn>model\n",
        "OK<end_of_turn>\n",
        "<start_of_turn>user\n",
        "Geoffrey Hinton: I am particularly proud of the fact that one of my students (Ilya Sutskever) fired Sam Altman.<end_of_turn>\n",
        "<start_of_turn>model\n",
        "\"\"\"\n",
        "\n",
        "os.environ['BASE_URL'] = \"https://huggingface.co/webbigdata/gemma-2-2b-jpn-it-translate-gguf/resolve/main/gemma-2-2b-jpn-it-translate\""
      ],
      "metadata": {
        "id": "c94toQkYzxpk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ygJ-cNOc_qTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4dea444-bbfa-4c52-e7df-97ffad47d858",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I ccache not found. Consider installing it for faster compilation.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion \n",
            "I CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE \n",
            "I NVCCFLAGS: -std=c++11 -O3 -g \n",
            "I LDFLAGS:    \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE  examples/deprecation-warning/deprecation-warning.o -o main  \n",
            "c++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE  examples/deprecation-warning/deprecation-warning.o -o server  \n",
            "NOTICE: The 'main' binary is deprecated. Please use 'llama-cli' instead.\n",
            "NOTICE: The 'server' binary is deprecated. Please use 'llama-server' instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "fatal: destination path 'llama.cpp' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# setup llama.cpp\n",
        "git clone https://github.com/ggerganov/llama.cpp.git\n",
        "cd llama.cpp\n",
        "make -j"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gemma-2-2b-jpn-it-translate-IQ3_XXS.gguf"
      ],
      "metadata": {
        "id": "0stV04t7MQm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd llama.cpp\n",
        "wget ${BASE_URL}-IQ3_XXS.gguf 2>>IQ3_XXS.gguf.log"
      ],
      "metadata": {
        "id": "o6LdO72RMQyS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd llama.cpp && ./llama-cli -e --temp 0 --repeat-penalty 1.0 -n -2 -m 'gemma-2-2b-jpn-it-translate-IQ3_XXS.gguf' -p \"$TRANSLATE_TEMPLATE_Ja\" 2>Q3_K_M.log"
      ],
      "metadata": {
        "id": "ayZUdGQXMaZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d0186b-efc1-4c47-fa7a-2263ba4e544c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user\n",
            "You are a highly skilled professional Japanese-English and English-Japanese translator. Translate the given text accurately, taking into account the context and specific instructions provided. Steps may include hints enclosed in square brackets [] with the key and value separated by a colon:. Only when the subject is specified in the Japanese sentence, the subject will be added when translating into English. If no additional instructions or context are provided, use your expertise to consider what the most appropriate context is and provide a natural translation that aligns with that context. When translating, strive to faithfully reflect the meaning and tone of the original text, pay attention to cultural nuances and differences in language usage, and ensure that the translation is grammatically correct and easy to read. After completing the translation, review it once more to check for errors or unnatural expressions. For technical terms and proper nouns, either leave them in the original language or use appropriate translations as necessary. Take a deep breath, calm down, and start translating.\n",
            "\n",
            "Translate Japanese to English.\n",
            "When translating, please use the following hints:\n",
            "[writeing_style: web-fiction]\n",
            "[羂索: Kenjyaku]\n",
            "model\n",
            "OK\n",
            "user\n",
            "羂索 （美しい、本気の土下座だ…私がこの域に達したのは20代後半……)\n",
            "model\n",
            "Kenjyaku (Beautiful, genuine kneeling... I reached this age in my late twenties...) [end of text]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd llama.cpp && ./llama-cli -e --temp 0 --repeat-penalty 1.0 -n -2 -m 'gemma-2-2b-jpn-it-translate-IQ3_XXS.gguf' -p \"$TRANSLATE_TEMPLATE_En\" 2>>Q3_K_M.log"
      ],
      "metadata": {
        "id": "wZva70fHMdO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7efa76-85c2-4686-8d38-435d690b781c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user\n",
            "You are a highly skilled professional Japanese-English and English-Japanese translator. Translate the given text accurately, taking into account the context and specific instructions provided. Steps may include hints enclosed in square brackets [] with the key and value separated by a colon:. Only when the subject is specified in the Japanese sentence, the subject will be added when translating into English. If no additional instructions or context are provided, use your expertise to consider what the most appropriate context is and provide a natural translation that aligns with that context. When translating, strive to faithfully reflect the meaning and tone of the original text, pay attention to cultural nuances and differences in language usage, and ensure that the translation is grammatically correct and easy to read. After completing the translation, review it once more to check for errors or unnatural expressions. For technical terms and proper nouns, either leave them in the original language or use appropriate translations as necessary. Take a deep breath, calm down, and start translating.\n",
            "\n",
            "Translate English to Japanese.\n",
            "When translating, please use the following hints:\n",
            "[writing_style: casual, nsfw]\n",
            "[Geoffrey Hinton: ジェフェリー・ヒントン]\n",
            "[Sam Altman: サム・アルトマン]\n",
            "[Ilya Sutskever: イリヤ・サツケバー]\n",
            "model\n",
            "OK\n",
            "user\n",
            "Geoffrey Hinton: I am particularly proud of the fact that one of my students (Ilya Sutskever) fired Sam Altman.\n",
            "model\n",
            "ジェフェリー・ヒントン: 特に、私の学生の一人がサム・アルトマンを解雇したという事実に誇りに思っています。 [end of text]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gemma-2-2b-jpn-it-translate-Q4_K_L.gguf"
      ],
      "metadata": {
        "id": "kvk71HW6OFEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd llama.cpp\n",
        "wget ${BASE_URL}-Q4_K_L.gguf 2>>q4_k.log"
      ],
      "metadata": {
        "id": "Tl3p1jLJOFEp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd llama.cpp && ./llama-cli -e --temp 0 --repeat-penalty 1.0 -n -2 -m 'gemma-2-2b-jpn-it-translate-Q4_K_L.gguf' -p \"$TRANSLATE_TEMPLATE_Ja\" 2>Q4_K.log"
      ],
      "metadata": {
        "id": "FX4PDXqSOFEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ccc1c2-bd3b-4fb4-9c92-535f64afb0a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user\n",
            "You are a highly skilled professional Japanese-English and English-Japanese translator. Translate the given text accurately, taking into account the context and specific instructions provided. Steps may include hints enclosed in square brackets [] with the key and value separated by a colon:. Only when the subject is specified in the Japanese sentence, the subject will be added when translating into English. If no additional instructions or context are provided, use your expertise to consider what the most appropriate context is and provide a natural translation that aligns with that context. When translating, strive to faithfully reflect the meaning and tone of the original text, pay attention to cultural nuances and differences in language usage, and ensure that the translation is grammatically correct and easy to read. After completing the translation, review it once more to check for errors or unnatural expressions. For technical terms and proper nouns, either leave them in the original language or use appropriate translations as necessary. Take a deep breath, calm down, and start translating.\n",
            "\n",
            "Translate Japanese to English.\n",
            "When translating, please use the following hints:\n",
            "[writeing_style: web-fiction]\n",
            "[羂索: Kenjyaku]\n",
            "model\n",
            "OK\n",
            "user\n",
            "羂索 （美しい、本気の土下座だ…私がこの域に達したのは20代後半……)\n",
            "model\n",
            "Kenjyaku (Beautiful, this is a genuine bow... I've reached this age in my late 20s...) [end of text]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd llama.cpp && ./llama-cli -e --temp 0 --repeat-penalty 1.0 -n -2 -m 'gemma-2-2b-jpn-it-translate-Q4_K_L.gguf' -p \"$TRANSLATE_TEMPLATE_En\" 2>>Q4_K.log"
      ],
      "metadata": {
        "id": "HX8Z7FMKOFEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "564ecfb8-0ef6-4141-87ee-b453f5998f3f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user\n",
            "You are a highly skilled professional Japanese-English and English-Japanese translator. Translate the given text accurately, taking into account the context and specific instructions provided. Steps may include hints enclosed in square brackets [] with the key and value separated by a colon:. Only when the subject is specified in the Japanese sentence, the subject will be added when translating into English. If no additional instructions or context are provided, use your expertise to consider what the most appropriate context is and provide a natural translation that aligns with that context. When translating, strive to faithfully reflect the meaning and tone of the original text, pay attention to cultural nuances and differences in language usage, and ensure that the translation is grammatically correct and easy to read. After completing the translation, review it once more to check for errors or unnatural expressions. For technical terms and proper nouns, either leave them in the original language or use appropriate translations as necessary. Take a deep breath, calm down, and start translating.\n",
            "\n",
            "Translate English to Japanese.\n",
            "When translating, please use the following hints:\n",
            "[writing_style: casual, nsfw]\n",
            "[Geoffrey Hinton: ジェフェリー・ヒントン]\n",
            "[Sam Altman: サム・アルトマン]\n",
            "[Ilya Sutskever: イリヤ・サツケバー]\n",
            "model\n",
            "OK\n",
            "user\n",
            "Geoffrey Hinton: I am particularly proud of the fact that one of my students (Ilya Sutskever) fired Sam Altman.\n",
            "model\n",
            "ジェフェリー・ヒントン: 特に、学生の1人がサム・アルトマンを解雇したという事実を誇りに思っています。 [end of text]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 謝辞 Acknowledgment\n",
        "\n",
        "Original Base Model  \n",
        "[google/gemma-2-2b-jpn-it](https://huggingface.co/google/gemma-2-2b-jpn-it)  \n",
        "\n",
        "This gguf model  \n",
        "[webbigdata/gemma-2-2b-jpn-it-translate-gguf](https://huggingface.co/webbigdata/gemma-2-2b-jpn-it-translate-gguf)  \n",
        "\n",
        "This work was done by : [webbigdata](https://webbigdata.jp/)"
      ],
      "metadata": {
        "id": "pxPrR_5MI39q"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RgbYSzxcfWyYSgfiOoPy30SBrRS5k1Rl",
      "authorship_tag": "ABX9TyP7rZZOeUXjAsWU+F7XpeU4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}